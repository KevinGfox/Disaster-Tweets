{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2022-05-13T09:03:41.595951Z","iopub.execute_input":"2022-05-13T09:03:41.596214Z","iopub.status.idle":"2022-05-13T09:03:41.608038Z","shell.execute_reply.started":"2022-05-13T09:03:41.596187Z","shell.execute_reply":"2022-05-13T09:03:41.607218Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Import Tensorflow & Pathlib librairies\nimport pandas as pd \nimport numpy as np\nimport os\n\nfrom sklearn.model_selection import train_test_split\n\nimport spacy\nfrom spacy.lang.en.stop_words import STOP_WORDS\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Embedding, Dense, Dropout, GlobalAveragePooling1D\n\nimport plotly.express as px","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:30:08.034760Z","iopub.execute_input":"2022-06-04T07:30:08.035120Z","iopub.status.idle":"2022-06-04T07:30:23.843738Z","shell.execute_reply.started":"2022-06-04T07:30:08.035033Z","shell.execute_reply":"2022-06-04T07:30:23.842360Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"# Import Dataset\ndf= pd.read_csv('../input/nlp-getting-started/train.csv')","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:30:53.172651Z","iopub.execute_input":"2022-06-04T07:30:53.172940Z","iopub.status.idle":"2022-06-04T07:30:53.212811Z","shell.execute_reply.started":"2022-06-04T07:30:53.172913Z","shell.execute_reply":"2022-06-04T07:30:53.211593Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Diplay informations for the train set\ndisplay(df.head())\nprint()\nprint(df.info())\nprint()\ndisplay(df.describe(include='all'))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:30:55.264902Z","iopub.execute_input":"2022-06-04T07:30:55.265187Z","iopub.status.idle":"2022-06-04T07:30:55.353355Z","shell.execute_reply.started":"2022-06-04T07:30:55.265156Z","shell.execute_reply":"2022-06-04T07:30:55.352187Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"# Diplay informations for the test set\ndisplay(df_test.head())\nprint()\nprint(df_test.info())\nprint()\ndisplay(df_test.describe(include='all'))","metadata":{"execution":{"iopub.status.busy":"2022-05-21T07:54:37.891246Z","iopub.execute_input":"2022-05-21T07:54:37.891553Z","iopub.status.idle":"2022-05-21T07:54:37.930346Z","shell.execute_reply.started":"2022-05-21T07:54:37.891522Z","shell.execute_reply":"2022-05-21T07:54:37.929327Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"#                                 EDA","metadata":{}},{"cell_type":"code","source":"fig = px.histogram(df, \n                   y='keyword', \n                   color = 'target',\n                   title=\"Keywords count for the target\"\n                  )\nfig.update_layout(\n    autosize=False,\n    width=800,\n    height=1500,\n    margin=dict(l=50,r=50,b=50,t=50,pad=4),\n    paper_bgcolor=\"LightSteelBlue\",\n    barmode=\"relative\",\n    yaxis={'categoryorder':'total ascending'}\n)\nfig.update_yaxes(tickfont_size=10)\nfig.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:35:23.290666Z","iopub.execute_input":"2022-06-04T07:35:23.290941Z","iopub.status.idle":"2022-06-04T07:35:23.402328Z","shell.execute_reply.started":"2022-06-04T07:35:23.290911Z","shell.execute_reply":"2022-06-04T07:35:23.401736Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"fig2 = px.histogram(df, \n                   x='target',\n                   title=\"Target count in the training set\"\n                  )\nfig2.update_layout(\n    autosize=False,\n    width=500,\n    height=500,\n    margin=dict(l=50,r=50,b=50,t=50,pad=4),\n    paper_bgcolor=\"LightSteelBlue\"\n)\nfig2.show()       ","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:35:15.660164Z","iopub.execute_input":"2022-06-04T07:35:15.661412Z","iopub.status.idle":"2022-06-04T07:35:15.749207Z","shell.execute_reply.started":"2022-06-04T07:35:15.661335Z","shell.execute_reply":"2022-06-04T07:35:15.748557Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"#                             PREPROCESSING","metadata":{}},{"cell_type":"code","source":"# Import the english language model\nnlp = spacy.load(\"en_core_web_sm\")\n# Delete non int or spaces\ndf[\"text_clean\"] = df[\"text\"].apply(lambda x:''.join(ch for ch in x if ch.isalnum() or ch==\" \"))\n# Lower string and strip\ndf[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: x.lower().strip())\n# delete urls\ndf[\"text_clean\"] = df['text_clean'].str.replace(r\"http.*\",\"\")\n# Lematization\ndf[\"text_clean\"] = df[\"text_clean\"].apply(lambda x: \" \".join([token.lemma_ for token in nlp(x) if (token.lemma_ not in STOP_WORDS) and (token.text not in STOP_WORDS)]))\n\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:36:27.336750Z","iopub.execute_input":"2022-06-04T07:36:27.337041Z","iopub.status.idle":"2022-06-04T07:37:19.621190Z","shell.execute_reply.started":"2022-06-04T07:36:27.336986Z","shell.execute_reply":"2022-06-04T07:37:19.619897Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"# Check if there is any non-string in text_clean\ndf.text_clean.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:37:33.599461Z","iopub.execute_input":"2022-06-04T07:37:33.599735Z","iopub.status.idle":"2022-06-04T07:37:33.615960Z","shell.execute_reply.started":"2022-06-04T07:37:33.599705Z","shell.execute_reply":"2022-06-04T07:37:33.614744Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"# Clean it\nmask = df.text_clean.apply(lambda x: type(x)==str)\n# Check it\nmask.value_counts()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:37:42.265406Z","iopub.execute_input":"2022-06-04T07:37:42.266262Z","iopub.status.idle":"2022-06-04T07:37:42.280836Z","shell.execute_reply.started":"2022-06-04T07:37:42.266210Z","shell.execute_reply":"2022-06-04T07:37:42.279645Z"},"trusted":true},"execution_count":17,"outputs":[]},{"cell_type":"code","source":"# Filter dataset\ndf = df.loc[mask,:]","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:37:46.878670Z","iopub.execute_input":"2022-06-04T07:37:46.879229Z","iopub.status.idle":"2022-06-04T07:37:46.884518Z","shell.execute_reply.started":"2022-06-04T07:37:46.879196Z","shell.execute_reply":"2022-06-04T07:37:46.883633Z"},"trusted":true},"execution_count":19,"outputs":[]},{"cell_type":"code","source":"# instanciate the tokenizer and set it up to keep only the 1000 most common words\ntokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=1000)\n# Fit on text_clean\ntokenizer.fit_on_texts(df.text_clean)\n# Create new column\ndf[\"txt_encoded\"] = tokenizer.texts_to_sequences(df.text_clean)\ndf.head()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:38:05.379644Z","iopub.execute_input":"2022-06-04T07:38:05.379908Z","iopub.status.idle":"2022-06-04T07:38:05.627021Z","shell.execute_reply.started":"2022-06-04T07:38:05.379881Z","shell.execute_reply":"2022-06-04T07:38:05.626292Z"},"trusted":true},"execution_count":20,"outputs":[]},{"cell_type":"code","source":"# Store encoded texts into single numpy array of same length by adding zero padding at the end\ntext_pad = tf.keras.preprocessing.sequence.pad_sequences(df.txt_encoded, padding=\"post\")","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:47:48.411393Z","iopub.execute_input":"2022-06-04T07:47:48.411700Z","iopub.status.idle":"2022-06-04T07:47:48.451630Z","shell.execute_reply.started":"2022-06-04T07:47:48.411665Z","shell.execute_reply":"2022-06-04T07:47:48.450775Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"# Train Test Split\nxtrain, xval, ytrain, yval = train_test_split(text_pad,df.target, test_size=0.3)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:47:52.323806Z","iopub.execute_input":"2022-06-04T07:47:52.324143Z","iopub.status.idle":"2022-06-04T07:47:52.333616Z","shell.execute_reply.started":"2022-06-04T07:47:52.324104Z","shell.execute_reply":"2022-06-04T07:47:52.332071Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# create the tensor dataset for the training, and validation set\ntrain = tf.data.Dataset.from_tensor_slices((xtrain, ytrain))\nval = tf.data.Dataset.from_tensor_slices((xval, yval))","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:47:54.334016Z","iopub.execute_input":"2022-06-04T07:47:54.334299Z","iopub.status.idle":"2022-06-04T07:47:54.389742Z","shell.execute_reply.started":"2022-06-04T07:47:54.334269Z","shell.execute_reply":"2022-06-04T07:47:54.388925Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"code","source":"# Shuffle data and create batch on both set\ntrain_batch = train.shuffle(len(train)).batch(64)\nval_batch = val.shuffle(len(val)).batch(64)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:48:07.758415Z","iopub.execute_input":"2022-06-04T07:48:07.759383Z","iopub.status.idle":"2022-06-04T07:48:07.776317Z","shell.execute_reply.started":"2022-06-04T07:48:07.759314Z","shell.execute_reply":"2022-06-04T07:48:07.775437Z"},"trusted":true},"execution_count":25,"outputs":[]},{"cell_type":"code","source":"# Look at a batch of data\nfor tweet, meaning in train_batch.take(1):\n  print(tweet, meaning)","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:48:11.409294Z","iopub.execute_input":"2022-06-04T07:48:11.409563Z","iopub.status.idle":"2022-06-04T07:48:11.486221Z","shell.execute_reply.started":"2022-06-04T07:48:11.409535Z","shell.execute_reply":"2022-06-04T07:48:11.485301Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"#                         MODELING","metadata":{}},{"cell_type":"code","source":"vocab_size = tokenizer.num_words\nvocab_size","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:48:34.859238Z","iopub.execute_input":"2022-06-04T07:48:34.859523Z","iopub.status.idle":"2022-06-04T07:48:34.866753Z","shell.execute_reply.started":"2022-06-04T07:48:34.859494Z","shell.execute_reply":"2022-06-04T07:48:34.865967Z"},"trusted":true},"execution_count":27,"outputs":[]},{"cell_type":"code","source":"[df.shape]","metadata":{"execution":{"iopub.status.busy":"2022-06-04T07:48:36.187404Z","iopub.execute_input":"2022-06-04T07:48:36.187757Z","iopub.status.idle":"2022-06-04T07:48:36.195237Z","shell.execute_reply.started":"2022-06-04T07:48:36.187717Z","shell.execute_reply":"2022-06-04T07:48:36.194646Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"# Build the model\nmodel = tf.keras.Sequential([Embedding(vocab_size+1, 64, input_shape=[df.shape[1]], name=\"embedding\"),\n                             GlobalAveragePooling1D(),\n                             Dense(32,activation=\"relu\"),\n                             Dense(16, activation=\"relu\"),\n                             Dense(1, activation=\"sigmoid\")\n                            ])\nmodel.summary()","metadata":{"_kg_hide-output":true,"execution":{"iopub.status.busy":"2022-06-04T08:40:02.710368Z","iopub.execute_input":"2022-06-04T08:40:02.710693Z","iopub.status.idle":"2022-06-04T08:40:02.761982Z","shell.execute_reply.started":"2022-06-04T08:40:02.710660Z","shell.execute_reply":"2022-06-04T08:40:02.761079Z"},"trusted":true},"execution_count":98,"outputs":[]},{"cell_type":"code","source":"# Ce modèle donne avec opti (0.00005) + L2(0.001): \n# loss: 0.4019 - binary_accuracy: 0.8499 - val_loss: 0.5406 - val_binary_accuracy: 0.7776\nmodel = tf.keras.Sequential([Embedding(vocab_size+1, 64, input_shape=[df.shape[1]], name=\"embedding\"),\n                             GlobalAveragePooling1D(),\n                             Dense(32,activation=\"relu\",kernel_regularizer=l2(0.001)),\n                             Dense(16, activation=\"relu\",kernel_regularizer=l2(0.001)),\n                             Dense(1, activation=\"sigmoid\")\n                            ])\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-05-22T09:04:18.152836Z","iopub.execute_input":"2022-05-22T09:04:18.15311Z","iopub.status.idle":"2022-05-22T09:04:18.204252Z","shell.execute_reply.started":"2022-05-22T09:04:18.153082Z","shell.execute_reply":"2022-05-22T09:04:18.203284Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true,"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Set the optimizer \noptimizer= tf.keras.optimizers.Adam(0.00005)\n\n# Compile model with the optimizer, the loss fonction and the metrics\n# Binary Cross Entropy is the negative average of the log of corrected predicted probabilities.\n# Cross-entropy will calculate a score that summarizes the average difference between \n# the actual and predicted probability distributions for predicting class 1. \n# The score is minimized and a perfect cross-entropy value is 0.\nmodel.compile(optimizer=optimizer,\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.BinaryAccuracy()]\n             )","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:40:04.673432Z","iopub.execute_input":"2022-06-04T08:40:04.673794Z","iopub.status.idle":"2022-06-04T08:40:04.689151Z","shell.execute_reply.started":"2022-06-04T08:40:04.673753Z","shell.execute_reply":"2022-06-04T08:40:04.688301Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"history = model.fit(train_batch, \n                    epochs=100, \n                    validation_data=val_batch\n                   )","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:40:06.436315Z","iopub.execute_input":"2022-06-04T08:40:06.437031Z","iopub.status.idle":"2022-06-04T08:41:02.174746Z","shell.execute_reply.started":"2022-06-04T08:40:06.436980Z","shell.execute_reply":"2022-06-04T08:41:02.173498Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"import matplotlib.pyplot as plt\n\n# Visualization of the training process on the loss function \nplt.plot(history.history[\"loss\"], color=\"b\")\nplt.plot(history.history[\"val_loss\"], color=\"r\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:41:08.894089Z","iopub.execute_input":"2022-06-04T08:41:08.894428Z","iopub.status.idle":"2022-06-04T08:41:09.056787Z","shell.execute_reply.started":"2022-06-04T08:41:08.894391Z","shell.execute_reply":"2022-06-04T08:41:09.056194Z"},"trusted":true},"execution_count":101,"outputs":[]},{"cell_type":"code","source":"plt.plot(history.history[\"binary_accuracy\"], color=\"b\")\nplt.plot(history.history[\"val_binary_accuracy\"], color=\"r\")\nplt.ylabel(\"acurracy\")\nplt.xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:41:10.943163Z","iopub.execute_input":"2022-06-04T08:41:10.943508Z","iopub.status.idle":"2022-06-04T08:41:11.118924Z","shell.execute_reply.started":"2022-06-04T08:41:10.943469Z","shell.execute_reply":"2022-06-04T08:41:11.117883Z"},"trusted":true},"execution_count":102,"outputs":[]},{"cell_type":"markdown","source":"# learning rate (0.00005) with Adam optimizer :\n# 55 epochs: \nloss: 0.3928 - binary_accuracy: 0.8364 - val_loss: 0.4609 - val_binary_accuracy: 0.7960\n> Test new model with dropout layers and more dense layer","metadata":{}},{"cell_type":"code","source":"# Ce modèle donne avec opti (0.00005): \n# 50 epochs: loss: 0.4260 - binary_accuracy: 0.8296 - val_loss: 0.4655 - val_binary_accuracy: 0.7938\nmodel2 = tf.keras.Sequential([Embedding(vocab_size+1, 64, input_shape=[df.shape[1]], name=\"embedding\"),\n                             GlobalAveragePooling1D(),\n                             Dense(32,activation=\"relu\"),\n                             Dropout(0.2),\n                             Dense(16, activation=\"relu\"),\n                             Dropout(0.2),\n                             Dense(8, activation=\"relu\"),\n                             Dropout(0.2),\n                             Dense(1, activation=\"sigmoid\")\n                            ])\nmodel2.summary()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:35:49.721761Z","iopub.execute_input":"2022-06-04T08:35:49.722378Z","iopub.status.idle":"2022-06-04T08:35:49.786304Z","shell.execute_reply.started":"2022-06-04T08:35:49.722339Z","shell.execute_reply":"2022-06-04T08:35:49.784818Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"model2.compile(optimizer=optimizer,\n              loss=tf.keras.losses.BinaryCrossentropy(),\n              metrics=[tf.keras.metrics.BinaryAccuracy()]\n             )","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:35:49.805802Z","iopub.execute_input":"2022-06-04T08:35:49.806088Z","iopub.status.idle":"2022-06-04T08:35:49.824121Z","shell.execute_reply.started":"2022-06-04T08:35:49.806054Z","shell.execute_reply":"2022-06-04T08:35:49.822628Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"code","source":"history2 = model2.fit(train_batch, \n                    epochs=100, \n                    validation_data=val_batch\n                   )","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:35:49.825730Z","iopub.execute_input":"2022-06-04T08:35:49.826075Z","iopub.status.idle":"2022-06-04T08:36:40.971628Z","shell.execute_reply.started":"2022-06-04T08:35:49.826020Z","shell.execute_reply":"2022-06-04T08:36:40.970138Z"},"collapsed":true,"jupyter":{"outputs_hidden":true},"trusted":true},"execution_count":95,"outputs":[]},{"cell_type":"code","source":"plt.plot(history2.history[\"loss\"], color=\"b\")\nplt.plot(history2.history[\"val_loss\"], color=\"r\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:36:40.973412Z","iopub.execute_input":"2022-06-04T08:36:40.973705Z","iopub.status.idle":"2022-06-04T08:36:41.124738Z","shell.execute_reply.started":"2022-06-04T08:36:40.973669Z","shell.execute_reply":"2022-06-04T08:36:41.124211Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"plt.plot(history2.history[\"binary_accuracy\"], color=\"b\")\nplt.plot(history2.history[\"val_binary_accuracy\"], color=\"r\")\nplt.ylabel(\"acurracy\")\nplt.xlabel(\"Epochs\")\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-06-04T08:36:41.125693Z","iopub.execute_input":"2022-06-04T08:36:41.126435Z","iopub.status.idle":"2022-06-04T08:36:41.263842Z","shell.execute_reply.started":"2022-06-04T08:36:41.126405Z","shell.execute_reply":"2022-06-04T08:36:41.263273Z"},"trusted":true},"execution_count":97,"outputs":[]},{"cell_type":"markdown","source":"# learning rate (0.00005) with Adam optimizer :\n# 39 epochs: \nloss: 0.4331 - binary_accuracy: 0.8283 - val_loss: 0.4596 - val_binary_accuracy: 0.7929\n\n> Second model is equivalent to the first","metadata":{}}]}